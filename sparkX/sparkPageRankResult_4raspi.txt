

======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 1
0: ('498956', 1.5950000000000004)
1: ('423723', 1.085)
2: ('182512', 1.17)
3: ('334860', 1.0)
4: ('430315', 1.0849999999999997)
5: ('13079', 1.0849999999999997)
6: ('99320', 0.575)
7: ('467985', 0.9149999999999999)
8: ('377929', 0.575)
9: ('331765', 1.34)
Start time: 2021-12-17 07:57:52.389724
End time: 2021-12-17 08:00:09.070147
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 1
Run time (secs): 136.680423


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 2
0: ('456855', 0.708875)
1: ('390758', 0.934975)
2: ('258581', 1.4322249999999999)
3: ('420561', 1.218875)
4: ('305747', 0.915)
5: ('450652', 0.681675)
6: ('350083', 0.835525)
7: ('451245', 1.0216749999999999)
8: ('134743', 0.893325)
9: ('419648', 1.3978)
Start time: 2021-12-17 08:00:31.825041
End time: 2021-12-17 08:03:17.918941
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 2
Run time (secs): 166.0939


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 4
0: ('172828', 1.0995221118749998)
1: ('113664', 1.0592727182638888)
2: ('52621', 1.0482840375)
3: ('406035', 1.3348683811805553)
4: ('56438', 1.331119451458333)
5: ('264255', 1.1122905332638884)
6: ('202121', 1.1278061581944443)
7: ('79872', 1.708589886944444)
8: ('128402', 0.8301370518749999)
9: ('312911', 1.0647379113194444)
Start time: 2021-12-17 08:03:41.257292
End time: 2021-12-17 08:07:06.584391
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 4
Run time (secs): 205.327099


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 8
0: ('75831', 1.3219135498063652)
1: ('361224', 1.15184603917301)
2: ('280441', 1.2045839819528963)
3: ('493950', 0.7359668430231117)
4: ('416921', 0.7983172861474763)
5: ('101107', 1.0892377501136998)
6: ('290326', 0.9193571401444749)
7: ('220543', 1.3224168842162107)
8: ('132698', 1.153084482256494)
9: ('174688', 1.0665112012220535)
Start time: 2021-12-17 08:07:29.644057
End time: 2021-12-17 08:12:59.832975
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 8
Run time (secs): 330.188918


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 12
0: ('218008', 1.0533292133501455)
1: ('156390', 1.7973381678103733)
2: ('399608', 1.150228502882744)
3: ('180036', 0.6939871398251628)
4: ('222012', 1.1247687465253364)
5: ('380256', 1.1636774308611006)
6: ('477331', 1.2091664156265078)
7: ('260207', 1.184272643350549)
8: ('283734', 1.0037115373812817)
9: ('22863', 1.188161859262435)
Start time: 2021-12-17 08:13:22.296598
End time: 2021-12-17 08:21:03.704898
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 12
Run time (secs): 461.4083


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 1
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 18 in stage 0.0 failed 4 times, most recent failure: Lost task 18.3 in stage 0.0 (TID 44) (192.168.99.205 executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 2
0: ('385242', 1.0510781330653478)
1: ('208982', 0.8667061487322205)
2: ('110730', 1.1305069541373334)
3: ('4998', 0.9282137669037314)
4: ('282875', 0.9295332828282828)
5: ('306911', 0.9245488375560785)
6: ('376672', 0.9988359871160587)
7: ('7458', 1.1366770247371676)
8: ('244179', 1.0424737850958568)
9: ('428477', 1.0411883680210683)
Start time: 2021-12-17 09:05:42.865032
End time: 2021-12-17 10:04:44.847252
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 2
Run time (secs): 3541.98222


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 4
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 0.0 failed 4 times, most recent failure: Lost task 8.3 in stage 0.0 (TID 56) (192.168.99.207 executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 8
0: ('378524', 1.2197415426817133)
1: ('266381', 1.0004988845535927)
2: ('31323', 1.0715764054958237)
3: ('92662', 0.9960129993809127)
4: ('248755', 1.2900918152436702)
5: ('416576', 0.9921240986930451)
6: ('104211', 1.002630556799292)
7: ('427816', 1.047615950040759)
8: ('410136', 0.9734600023303737)
9: ('190162', 1.0510908657090852)
Start time: 2021-12-17 11:13:41.859606
End time: 2021-12-17 12:29:59.564753
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 8
Run time (secs): 4577.705147


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 12
0: ('329270', 1.052761485213029)
1: ('6799', 1.028104260879882)
2: ('458421', 0.8760458678077562)
3: ('457710', 0.9641124151849327)
4: ('66276', 1.067394169811892)
5: ('8532', 0.9461996941393623)
6: ('245575', 0.9542130401719843)
7: ('364375', 1.285797351966654)
8: ('143069', 0.8425745546829974)
9: ('418693', 0.96039992254654)
Start time: 2021-12-17 12:30:21.198167
End time: 2021-12-17 13:05:53.146039
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 12
Run time (secs): 2131.947872


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 1
0: ('3863215', 1.34)
1: ('4652173', 0.9149999999999999)
2: ('210559', 1.255)
3: ('2005733', 0.745)
4: ('4575051', 1.17)
5: ('2471906', 1.9349999999999998)
6: ('863744', 1.085)
7: ('2859238', 1.255)
8: ('2157296', 1.4250000000000003)
9: ('368120', 0.66)
Start time: 2021-12-17 13:06:14.319475
End time: 2021-12-17 13:34:50.635774
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 1
Run time (secs): 1716.316299


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 2
0: ('2746682', 0.750525)
1: ('3674876', 0.8822749999999999)
2: ('3835882', 1.207825)
3: ('141702', 1.390575)
4: ('3948697', 0.963875)
5: ('301142', 1.3255499999999998)
6: ('4618702', 1.2099499999999999)
7: ('2862446', 0.9800249999999999)
8: ('2041559', 0.9728)
9: ('3657359', 1.034425)
Start time: 2021-12-17 13:35:13.185001
End time: 2021-12-17 14:09:56.369454
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 2
Run time (secs): 2083.184453


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 4
0: ('2738197', 0.7682699612499999)
1: ('2263448', 1.0363887125)
2: ('2040751', 1.1858264049999998)
3: ('4515919', 1.0216865174999998)
4: ('4692624', 1.102289425)
5: ('2439588', 1.675271418125)
6: ('3358203', 1.7566876374999993)
7: ('1043558', 0.9222127175)
8: ('4913300', 1.2851831599999997)
9: ('2334917', 1.1523061131249996)
Start time: 2021-12-17 14:10:18.508090
End time: 2021-12-17 14:55:51.751010
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 4
Run time (secs): 2733.24292


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 8
0: ('530061', 1.003362907528869)
1: ('3308162', 1.076212780276372)
2: ('3929568', 0.8062985297324463)
3: ('310963', 1.1565076175080915)
4: ('1603578', 1.0960615888476042)
5: ('677551', 1.1656050586240276)
6: ('1188426', 0.6235328499197962)
7: ('2247590', 1.4187972976167265)
8: ('4147171', 1.735886795700515)
9: ('3650366', 1.411402992566633)
Start time: 2021-12-17 14:56:14.285207
End time: 2021-12-17 16:03:30.401726
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 8
Run time (secs): 4036.116519


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 12
0: ('798595', 1.7385591677105399)
1: ('648431', 1.233477497521411)
2: ('1561885', 1.0106157908204942)
3: ('2592716', 1.5377548204693499)
4: ('2585227', 1.11537979853061)
5: ('2204541', 1.393921314581441)
6: ('86266', 0.8350173017772945)
7: ('1177278', 1.0612075031088362)
8: ('1124384', 0.6341768771059235)
9: ('1177434', 1.1276570962366639)
Start time: 2021-12-17 16:03:53.171810
End time: 2021-12-17 17:32:01.245231
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 12
Run time (secs): 5288.073421


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 1
0: ('2778286', 2.7003069759030542)
1: ('3158482', 0.8101992337164751)
2: ('92995', 123.42546851555542)
3: ('482374', 0.3679081211442028)
4: ('469335', 5.869318515503301)
5: ('3481049', 1.659608345318711)
6: ('2849098', 0.21773839267769315)
7: ('501586', 0.8976027277187913)
8: ('279309', 12.017746162956177)
9: ('1451559', 0.7997596153846154)
Start time: 2021-12-17 17:32:26.472168
End time: 2021-12-17 18:08:45.164936
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 1
Run time (secs): 2178.692768


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 2
0: ('887637', 2.5111197657834987)
1: ('36902', 5.482716407549507)
2: ('36873', 2.4918548315673754)
3: ('1631832', 0.5343690265099107)
4: ('62067', 2.48708023280253)
5: ('2512229', 0.5339151788418653)
6: ('29048', 3.8122005115684887)
7: ('468031', 6.511362786508547)
8: ('279318', 6.077431865973605)
9: ('533188', 3.673410482499753)
Start time: 2021-12-17 18:09:07.754392
End time: 2021-12-17 18:48:32.357162
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 2
Run time (secs): 2364.60277


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 4
0: ('1220', 358.0336831244451)
1: ('202357', 3.361902673657858)
2: ('1485631', 1.2612676246971712)
3: ('1485709', 1.283835574160681)
4: ('1485617', 1.8906062067264993)
5: ('184478', 0.42141032497722264)
6: ('358818', 1.9998670784916404)
7: ('3332703', 0.6605144419781371)
8: ('23631', 43.798655479704166)
9: ('817690', 0.7518819710480581)
Start time: 2021-12-17 18:48:54.605935
End time: 2021-12-17 19:38:34.358537
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 4
Run time (secs): 2979.752602


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 8
0: ('2276579', 0.6764892850398907)
1: ('270513', 4.71989609412383)
2: ('711749', 4.074082519772443)
3: ('77868', 5.846900696750833)
4: ('639612', 11.177352139545814)
5: ('2287044', 2.3767901800559996)
6: ('400797', 3.5110060059939254)
7: ('462685', 0.755781195657793)
8: ('503946', 3.0161146956610008)
9: ('1973270', 0.19550972464294408)
Start time: 2021-12-17 19:38:56.981808
End time: 2021-12-17 20:50:29.370964
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 8
Run time (secs): 4292.389156


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 12
0: ('1642823', 1.2877243491952504)
1: ('369776', 3.5636593555884613)
2: ('1636553', 0.8160608580474267)
3: ('151018', 0.8169577361945425)
4: ('1087464', 0.339382600778082)
5: ('4470244', 0.5299397925554199)
6: ('295263', 4.286791526064734)
7: ('156098', 4.328695603346311)
8: ('151015', 4.480325239616674)
9: ('551822', 2.968472085343218)
Start time: 2021-12-17 20:50:51.777838
End time: 2021-12-17 22:24:51.150823
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 12
Run time (secs): 5639.372985


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 1
0: ('302219', 1.34)
1: ('209558', 0.83)
2: ('369325', 0.83)
3: ('491602', 0.9149999999999999)
4: ('157554', 1.5100000000000002)
5: ('331416', 1.8500000000000003)
6: ('19970', 1.255)
7: ('473545', 0.9999999999999999)
8: ('303827', 1.3399999999999999)
9: ('162049', 1.255)
Start time: 2021-12-17 22:25:13.643461
End time: 2021-12-17 22:27:04.860754
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 1
Run time (secs): 111.217293


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 2
0: ('198307', 1.32385)
1: ('46254', 0.9132999999999999)
2: ('305360', 0.553325)
3: ('332111', 1.1971999999999998)
4: ('214365', 1.2278)
5: ('88681', 0.9511249999999999)
6: ('322360', 1.4556)
7: ('43749', 0.8733500000000001)
8: ('62826', 0.766675)
9: ('457083', 0.575)
Start time: 2021-12-17 22:27:26.104928
End time: 2021-12-17 22:29:43.355422
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 2
Run time (secs): 137.250494


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 4
0: ('111214', 0.9419716474999998)
1: ('232291', 1.4029444656249999)
2: ('360876', 0.92191617375)
3: ('191898', 1.089571415694444)
4: ('1993', 0.4959322668749999)
5: ('327321', 1.1081875962499999)
6: ('227250', 1.1318421435416666)
7: ('262059', 0.3904331356249999)
8: ('444229', 0.6252802199999999)
9: ('197979', 1.1589956225694442)
Start time: 2021-12-17 22:30:04.114724
End time: 2021-12-17 22:33:11.829037
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 4
Run time (secs): 187.714313


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 8
0: ('448832', 1.2806874342722083)
1: ('28510', 0.9434136188249236)
2: ('68131', 0.8678673203866942)
3: ('251573', 1.6123227825572746)
4: ('11283', 0.5697752886275126)
5: ('219139', 1.1533683105378054)
6: ('154277', 0.8493314733603077)
7: ('66554', 1.2408869768686919)
8: ('258915', 1.246241820625033)
9: ('136651', 0.8790465471404092)
Start time: 2021-12-17 22:33:31.243116
End time: 2021-12-17 22:38:30.349891
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 8
Run time (secs): 299.106775


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 12
0: ('358129', 0.9803769715842041)
1: ('270356', 1.239199487138327)
2: ('46059', 1.1106468854513634)
3: ('323030', 1.5225694329454311)
4: ('255876', 0.6520590174181873)
5: ('210534', 0.9828483706523807)
6: ('370256', 0.6375850278096266)
7: ('418257', 1.2207462726977802)
8: ('415465', 0.9058443933160247)
9: ('215693', 1.321078169404723)
Start time: 2021-12-17 22:38:49.855088
End time: 2021-12-17 22:46:18.084283
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 12
Run time (secs): 448.229195


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 1
0: ('75234', 0.8896717171717173)
1: ('262085', 0.9660858585858587)
2: ('138651', 1.0085000000000004)
3: ('292580', 1.0596717171717172)
4: ('17332', 0.9660000000000003)
5: ('183182', 1.051085858585859)
6: ('379064', 1.1020858585858588)
7: ('124599', 1.0596717171717172)
8: ('436306', 0.9830000000000003)
9: ('491995', 1.110585858585859)
Start time: 2021-12-17 22:46:55.724842
End time: 2021-12-17 23:05:24.855318
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 1
Run time (secs): 1109.130476


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 2
0: ('271948', 0.9297485881261597)
1: ('271528', 1.062434575499897)
2: ('23113', 0.9581439690311695)
3: ('158683', 1.055390522469594)
4: ('320305', 1.1375922492269637)
5: ('288255', 1.0050247169140385)
6: ('325920', 1.0431339836126035)
7: ('343942', 0.9984399362028864)
8: ('64304', 0.9907378200412702)
9: ('49923', 1.0482858532776749)
Start time: 2021-12-17 23:05:45.184601
End time: 2021-12-17 23:26:21.576171
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 2
Run time (secs): 1236.39157


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 4
0: ('320762', 0.882807511298521)
1: ('98010', 1.004980420356393)
2: ('348580', 0.9810565686813382)
3: ('493152', 0.9540295929230512)
4: ('348655', 1.0211227365367057)
5: ('486802', 0.8934583035771818)
6: ('45744', 1.1388224652329517)
7: ('466359', 1.0292800663707915)
8: ('304332', 0.9075695367874783)
9: ('83781', 0.9020968425585775)
Start time: 2021-12-17 23:26:42.835086
End time: 2021-12-17 23:49:17.907081
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 4
Run time (secs): 1355.071995


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 8
0: ('73343', 0.9192589931372159)
1: ('127508', 0.9196447366202376)
2: ('477772', 1.0431588834273504)
3: ('62959', 1.0414807307343172)
4: ('402040', 1.0478497780338922)
5: ('51291', 0.9687756066907391)
6: ('152550', 0.9624756072061782)
7: ('388796', 1.0026320947865224)
8: ('211257', 1.2005412264019089)
9: ('425400', 0.9761428281267966)
Start time: 2021-12-17 23:49:38.300502
End time: 2021-12-18 00:18:20.697014
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 8
Run time (secs): 1722.396512


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 12
0: ('488607', 0.9119197794703293)
1: ('348236', 0.9748852383414284)
2: ('291907', 1.0592355682383419)
3: ('199886', 1.0822265951267618)
4: ('317149', 0.9283487553780965)
5: ('269281', 0.9758995009211057)
6: ('473917', 0.9891180756241092)
7: ('310219', 0.9535346277841334)
8: ('101209', 1.0255734467971964)
9: ('207864', 0.916000749760833)
Start time: 2021-12-18 00:18:40.663061
End time: 2021-12-18 00:55:37.089985
File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 12
Run time (secs): 2216.426924


======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 1
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-36ff572b-4c3b-49e7-ab22-41da99196337/executor-2a402264-d158-4857-a80d-cbfbf680014f/blockmgr-a2631249-d6fa-4fb0-a16f-40a8d849fa24/12/shuffle_3_252_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-36ff572b-4c3b-49e7-ab22-41da99196337/executor-2a402264-d158-4857-a80d-cbfbf680014f/blockmgr-a2631249-d6fa-4fb0-a16f-40a8d849fa24/12/shuffle_3_252_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlocks(ShuffleBlockFetcherIterator.scala:516) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4$adapted(ShuffleBlockFetcherIterator.scala:562) 	at scala.Option.foreach(Option.scala:407) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52) 	at org.apache.spark.scheduler.Task.run(Task.scala:131) 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500) 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 2
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-8c7cc516-a724-473d-93e5-575ab114c88d/executor-bd49e0e0-7e3c-4eb6-8176-00c2182ca422/blockmgr-fdedfeae-5904-453d-89ff-59e5e31b834f/38/shuffle_5_168_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-8c7cc516-a724-473d-93e5-575ab114c88d/executor-bd49e0e0-7e3c-4eb6-8176-00c2182ca422/blockmgr-fdedfeae-5904-453d-89ff-59e5e31b834f/38/shuffle_5_168_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlocks(ShuffleBlockFetcherIterator.scala:516) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4$adapted(ShuffleBlockFetcherIterator.scala:562) 	at scala.Option.foreach(Option.scala:407) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52) 	at org.apache.spark.scheduler.Task.run(Task.scala:131) 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500) 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 4
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-9bad3c7e-a6b8-4694-a7b2-72484e9f3d99/executor-841666bc-308c-40f6-a24a-3ee05c93ac77/blockmgr-4b955180-ba26-4803-bd3e-dbea20c912de/28/shuffle_6_211_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-9bad3c7e-a6b8-4694-a7b2-72484e9f3d99/executor-841666bc-308c-40f6-a24a-3ee05c93ac77/blockmgr-4b955180-ba26-4803-bd3e-dbea20c912de/28/shuffle_6_211_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchHostLocalBlocks$6(ShuffleBlockFetcherIterator.scala:501) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchHostLocalBlocks$6$adapted(ShuffleBlockFetcherIterator.scala:496) 	at org.apache.spark.storage.HostLocalDirManager.$anonfun$getHostLocalDirs$1(BlockManager.scala:148) 	at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:859) 	at java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:837) 	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506) 	at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2073) 	at org.apache.spark.network.shuffle.BlockStoreClient$1.onSuccess(BlockStoreClient.java:119) 	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:195) 	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142) 	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53) 	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) 	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) 	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) 	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) 	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 8
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-36ff572b-4c3b-49e7-ab22-41da99196337/executor-1a35980a-9aa9-46b9-9b56-ee0668b382c3/blockmgr-0f9efbb2-36ff-4b22-af58-58d8683eaac7/25/shuffle_4_216_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-36ff572b-4c3b-49e7-ab22-41da99196337/executor-1a35980a-9aa9-46b9-9b56-ee0668b382c3/blockmgr-0f9efbb2-36ff-4b22-af58-58d8683eaac7/25/shuffle_4_216_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlocks(ShuffleBlockFetcherIterator.scala:516) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4$adapted(ShuffleBlockFetcherIterator.scala:562) 	at scala.Option.foreach(Option.scala:407) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52) 	at org.apache.spark.scheduler.Task.run(Task.scala:131) 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500) 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 12
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-36ff572b-4c3b-49e7-ab22-41da99196337/executor-453a9de8-b944-4569-bb92-8f25fb9a44de/blockmgr-f79ba011-b728-4c83-ae53-382409ee1c23/32/shuffle_25_179_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-36ff572b-4c3b-49e7-ab22-41da99196337/executor-453a9de8-b944-4569-bb92-8f25fb9a44de/blockmgr-f79ba011-b728-4c83-ae53-382409ee1c23/32/shuffle_25_179_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlocks(ShuffleBlockFetcherIterator.scala:516) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4$adapted(ShuffleBlockFetcherIterator.scala:562) 	at scala.Option.foreach(Option.scala:407) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52) 	at org.apache.spark.scheduler.Task.run(Task.scala:131) 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500) 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 1
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 21 in stage 0.2 failed 4 times, most recent failure: Lost task 21.3 in stage 0.2 (TID 157) (192.168.99.207 executor 21): ExecutorLostFailure (executor 21 exited caused by one of the running tasks) Reason: worker lost
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 2
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-9bad3c7e-a6b8-4694-a7b2-72484e9f3d99/executor-0e40732d-be8c-40c1-87b8-06f17b041de6/blockmgr-16e71dc2-1f83-4f73-b306-b8a20abcaf87/15/shuffle_5_396_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-9bad3c7e-a6b8-4694-a7b2-72484e9f3d99/executor-0e40732d-be8c-40c1-87b8-06f17b041de6/blockmgr-16e71dc2-1f83-4f73-b306-b8a20abcaf87/15/shuffle_5_396_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchHostLocalBlocks$6(ShuffleBlockFetcherIterator.scala:501) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchHostLocalBlocks$6$adapted(ShuffleBlockFetcherIterator.scala:496) 	at org.apache.spark.storage.HostLocalDirManager.$anonfun$getHostLocalDirs$1(BlockManager.scala:148) 	at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:859) 	at java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:837) 	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506) 	at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2073) 	at org.apache.spark.network.shuffle.BlockStoreClient$1.onSuccess(BlockStoreClient.java:119) 	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:195) 	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142) 	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53) 	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) 	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) 	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) 	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) 	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 4
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 12 in stage 0.0 failed 4 times, most recent failure: Lost task 12.3 in stage 0.0 (TID 71) (192.168.99.201 executor 22): ExecutorLostFailure (executor 22 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 148084 ms
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 8
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-533b3849-cc42-494e-8219-79affa87c11c/executor-2b041113-80d7-46c9-9a32-bf8861495d21/blockmgr-bea42b1a-bd38-4702-976a-39b2f37f196e/37/shuffle_4_201_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-533b3849-cc42-494e-8219-79affa87c11c/executor-2b041113-80d7-46c9-9a32-bf8861495d21/blockmgr-bea42b1a-bd38-4702-976a-39b2f37f196e/37/shuffle_4_201_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchHostLocalBlocks$6(ShuffleBlockFetcherIterator.scala:501) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchHostLocalBlocks$6$adapted(ShuffleBlockFetcherIterator.scala:496) 	at org.apache.spark.storage.HostLocalDirManager.$anonfun$getHostLocalDirs$1(BlockManager.scala:148) 	at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:859) 	at java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:837) 	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506) 	at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2073) 	at org.apache.spark.network.shuffle.BlockStoreClient$1.onSuccess(BlockStoreClient.java:119) 	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:195) 	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142) 	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53) 	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) 	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) 	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) 	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) 	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 12
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 0.0 failed 4 times, most recent failure: Lost task 15.3 in stage 0.0 (TID 66) (192.168.99.207 executor 18): ExecutorLostFailure (executor 18 exited caused by one of the running tasks) Reason: worker lost
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 1
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-36ff572b-4c3b-49e7-ab22-41da99196337/executor-b27f74c4-64e1-43fc-8246-cca04e178e55/blockmgr-d7ef368c-3fdd-41e1-bd41-5a116f89be69/02/shuffle_3_90_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-36ff572b-4c3b-49e7-ab22-41da99196337/executor-b27f74c4-64e1-43fc-8246-cca04e178e55/blockmgr-d7ef368c-3fdd-41e1-bd41-5a116f89be69/02/shuffle_3_90_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlocks(ShuffleBlockFetcherIterator.scala:516) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4$adapted(ShuffleBlockFetcherIterator.scala:562) 	at scala.Option.foreach(Option.scala:407) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52) 	at org.apache.spark.scheduler.Task.run(Task.scala:131) 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500) 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 2
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-4c321bea-53c3-40ec-9fc9-b9bacec180a2/executor-62c8b644-189d-4485-bebc-459837b456b8/blockmgr-7c841418-8ab7-440c-9220-300cdf64487c/23/shuffle_5_86_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-4c321bea-53c3-40ec-9fc9-b9bacec180a2/executor-62c8b644-189d-4485-bebc-459837b456b8/blockmgr-7c841418-8ab7-440c-9220-300cdf64487c/23/shuffle_5_86_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlocks(ShuffleBlockFetcherIterator.scala:516) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4$adapted(ShuffleBlockFetcherIterator.scala:562) 	at scala.Option.foreach(Option.scala:407) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52) 	at org.apache.spark.scheduler.Task.run(Task.scala:131) 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500) 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 4
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-36ff572b-4c3b-49e7-ab22-41da99196337/executor-da4e57d5-091a-4eae-b059-18ccc6b16cfe/blockmgr-0f02ede3-da28-4390-a7b7-53341d2bb2e7/00/shuffle_8_86_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-36ff572b-4c3b-49e7-ab22-41da99196337/executor-da4e57d5-091a-4eae-b059-18ccc6b16cfe/blockmgr-0f02ede3-da28-4390-a7b7-53341d2bb2e7/00/shuffle_8_86_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlocks(ShuffleBlockFetcherIterator.scala:516) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4$adapted(ShuffleBlockFetcherIterator.scala:562) 	at scala.Option.foreach(Option.scala:407) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52) 	at org.apache.spark.scheduler.Task.run(Task.scala:131) 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500) 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 8
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-36ff572b-4c3b-49e7-ab22-41da99196337/executor-aa76c1c9-b447-4e6b-9016-a98c5a43407e/blockmgr-50b00b6a-bc51-4469-ae17-ac37d60d22b0/04/shuffle_4_86_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-36ff572b-4c3b-49e7-ab22-41da99196337/executor-aa76c1c9-b447-4e6b-9016-a98c5a43407e/blockmgr-50b00b6a-bc51-4469-ae17-ac37d60d22b0/04/shuffle_4_86_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlocks(ShuffleBlockFetcherIterator.scala:516) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4$adapted(ShuffleBlockFetcherIterator.scala:562) 	at scala.Option.foreach(Option.scala:407) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52) 	at org.apache.spark.scheduler.Task.run(Task.scala:131) 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500) 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_10.out
Rounds: 12
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-b8186fd1-9310-41d4-85e1-07bd84172507/executor-4ffda187-bae3-4107-97ee-7a9492e59ac3/blockmgr-01441ca0-d208-4e61-8b4a-8b38484aefa3/25/shuffle_6_90_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-b8186fd1-9310-41d4-85e1-07bd84172507/executor-4ffda187-bae3-4107-97ee-7a9492e59ac3/blockmgr-01441ca0-d208-4e61-8b4a-8b38484aefa3/25/shuffle_6_90_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlocks(ShuffleBlockFetcherIterator.scala:516) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4$adapted(ShuffleBlockFetcherIterator.scala:562) 	at scala.Option.foreach(Option.scala:407) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52) 	at org.apache.spark.scheduler.Task.run(Task.scala:131) 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500) 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 1
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 17 in stage 0.0 failed 4 times, most recent failure: Lost task 17.3 in stage 0.0 (TID 69) (192.168.99.207 executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 2
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-9bad3c7e-a6b8-4694-a7b2-72484e9f3d99/executor-9c61314c-7de9-4f9d-a9b9-d259940444ea/blockmgr-9df68d95-5707-4899-b48e-ec21f58c5f0a/0a/shuffle_5_221_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-9bad3c7e-a6b8-4694-a7b2-72484e9f3d99/executor-9c61314c-7de9-4f9d-a9b9-d259940444ea/blockmgr-9df68d95-5707-4899-b48e-ec21f58c5f0a/0a/shuffle_5_221_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlocks(ShuffleBlockFetcherIterator.scala:516) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4$adapted(ShuffleBlockFetcherIterator.scala:562) 	at scala.Option.foreach(Option.scala:407) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52) 	at org.apache.spark.scheduler.Task.run(Task.scala:131) 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500) 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 4
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-8c7cc516-a724-473d-93e5-575ab114c88d/executor-e67747ce-9bc0-49fd-82ba-b878f721c6e1/blockmgr-505a3df0-c987-4f4d-9006-18c81f8f0e18/3b/shuffle_6_269_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-8c7cc516-a724-473d-93e5-575ab114c88d/executor-e67747ce-9bc0-49fd-82ba-b878f721c6e1/blockmgr-505a3df0-c987-4f4d-9006-18c81f8f0e18/3b/shuffle_6_269_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlocks(ShuffleBlockFetcherIterator.scala:516) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4$adapted(ShuffleBlockFetcherIterator.scala:562) 	at scala.Option.foreach(Option.scala:407) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52) 	at org.apache.spark.scheduler.Task.run(Task.scala:131) 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500) 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 8
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-8c7cc516-a724-473d-93e5-575ab114c88d/executor-01a08ccb-04f1-4813-b418-2d9943a8b14b/blockmgr-90e6e181-97c1-4966-9c1d-d31e8a0e7cc7/38/shuffle_17_204_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-8c7cc516-a724-473d-93e5-575ab114c88d/executor-01a08ccb-04f1-4813-b418-2d9943a8b14b/blockmgr-90e6e181-97c1-4966-9c1d-d31e8a0e7cc7/38/shuffle_17_204_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlocks(ShuffleBlockFetcherIterator.scala:516) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$initialize$4$adapted(ShuffleBlockFetcherIterator.scala:562) 	at scala.Option.foreach(Option.scala:407) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:562) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:171) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:85) 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:337) 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52) 	at org.apache.spark.scheduler.Task.run(Task.scala:131) 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500) 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_500000_100.out
Rounds: 12
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (groupByKey at /home/wcauser3/thesis_page_rank/sparkX/pageRank.py:63) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: /tmp/spark-b8186fd1-9310-41d4-85e1-07bd84172507/executor-2a89f5ca-1349-4bc6-a93c-585ee8e8d5b2/blockmgr-1a41bb0b-78f8-4df5-ba8a-c7d5d15f6034/30/shuffle_12_289_0.index 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) 	at scala.collection.Iterator.foreach(Iterator.scala:941) 	at scala.collection.Iterator.foreach$(Iterator.scala:941) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429) 	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307) 	at org.apache.spark.api.python.PythonRunner$$anon$2.writeIteratorToStream(PythonRunner.scala:621) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:397) 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996) 	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:232) Caused by: java.nio.file.AccessDeniedException: /tmp/spark-b8186fd1-9310-41d4-85e1-07bd84172507/executor-2a89f5ca-1349-4bc6-a93c-585ee8e8d5b2/blockmgr-1a41bb0b-78f8-4df5-ba8a-c7d5d15f6034/30/shuffle_12_289_0.index 	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) 	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) 	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:371) 	at java.base/java.nio.file.Files.newByteChannel(Files.java:422) 	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:351) 	at org.apache.spark.storage.BlockManager.getHostLocalShuffleData(BlockManager.scala:629) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchHostLocalBlock(ShuffleBlockFetcherIterator.scala:450) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2(ShuffleBlockFetcherIterator.scala:529) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$2$adapted(ShuffleBlockFetcherIterator.scala:528) 	at scala.collection.LinearSeqOptimized.forall(LinearSeqOptimized.scala:85) 	at scala.collection.LinearSeqOptimized.forall$(LinearSeqOptimized.scala:82) 	at scala.collection.immutable.List.forall(List.scala:89) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1(ShuffleBlockFetcherIterator.scala:528) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchMultipleHostLocalBlocks$1$adapted(ShuffleBlockFetcherIterator.scala:527) 	at scala.collection.Iterator.forall(Iterator.scala:953) 	at scala.collection.Iterator.forall$(Iterator.scala:951) 	at scala.collection.AbstractIterator.forall(Iterator.scala:1429) 	at scala.collection.IterableLike.forall(IterableLike.scala:77) 	at scala.collection.IterableLike.forall$(IterableLike.scala:76) 	at scala.collection.AbstractIterable.forall(Iterable.scala:56) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchMultipleHostLocalBlocks(ShuffleBlockFetcherIterator.scala:527) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchHostLocalBlocks$6(ShuffleBlockFetcherIterator.scala:501) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.$anonfun$fetchHostLocalBlocks$6$adapted(ShuffleBlockFetcherIterator.scala:496) 	at org.apache.spark.storage.HostLocalDirManager.$anonfun$getHostLocalDirs$1(BlockManager.scala:148) 	at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:859) 	at java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:837) 	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506) 	at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2073) 	at org.apache.spark.network.shuffle.BlockStoreClient$1.onSuccess(BlockStoreClient.java:119) 	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:195) 	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142) 	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53) 	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) 	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) 	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) 	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) 	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) 	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) 	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) 	at java.base/java.lang.Thread.run(Thread.java:829) 
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 1
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 11 in stage 0.0 failed 4 times, most recent failure: Lost task 11.3 in stage 0.0 (TID 62) (192.168.99.205 executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: worker lost
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 2
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 17 in stage 0.0 failed 4 times, most recent failure: Lost task 17.3 in stage 0.0 (TID 74) (192.168.99.205 executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: worker lost
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 4
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 22 in stage 0.0 failed 4 times, most recent failure: Lost task 22.3 in stage 0.0 (TID 59) (192.168.99.207 executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: worker lost
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 8
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 0.0 failed 4 times, most recent failure: Lost task 3.3 in stage 0.0 (TID 40) (192.168.99.205 executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 209532 ms
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/graph_5000000_10.out
Rounds: 12
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 14 in stage 0.0 failed 4 times, most recent failure: Lost task 14.3 in stage 0.0 (TID 53) (192.168.99.207 executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 1
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 0.0 failed 4 times, most recent failure: Lost task 2.3 in stage 0.0 (TID 65) (192.168.99.205 executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: worker lost
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 2
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 0.0 failed 4 times, most recent failure: Lost task 19.3 in stage 0.0 (TID 65) (192.168.99.207 executor 18): ExecutorLostFailure (executor 18 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 4
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 9 in stage 0.0 failed 4 times, most recent failure: Lost task 9.3 in stage 0.0 (TID 44) (192.168.99.207 executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Command exited with code 137
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 8
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 14 in stage 0.0 failed 4 times, most recent failure: Lost task 14.3 in stage 0.0 (TID 65) (192.168.99.207 executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



======================================


File: /home/wcauser3/thesis_page_rank/cpp/page_rank_with_redis/data/soc-LiveJournal1.out
Rounds: 12
Traceback (most recent call last):
  File "/home/wcauser3/thesis_page_rank/sparkX/pageRank.py", line 78, in <module>
    res = ranks.collect()
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/rdd.py", line 949, in collect
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/wcauser3/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 0.8 failed 4 times, most recent failure: Lost task 7.3 in stage 0.8 (TID 279) (192.168.99.205 executor 37): ExecutorLostFailure (executor 37 exited caused by one of the running tasks) Reason: worker lost
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)

